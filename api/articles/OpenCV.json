{"title":"OpenCV","uid":"cdd0edf7fdd8b10c4ae1947cffd17b2c","slug":"OpenCV","date":"2023-09-06T17:31:40.000Z","updated":"2023-09-10T09:07:18.790Z","comments":true,"path":"api/articles/OpenCV.json","keywords":null,"cover":[],"content":"<h1 id=\"传统视觉\"><a href=\"#传统视觉\" class=\"headerlink\" title=\"传统视觉\"></a>传统视觉</h1><h2 id=\"OpenCV\"><a href=\"#OpenCV\" class=\"headerlink\" title=\"OpenCV\"></a>OpenCV</h2><p>作为最基本的目标检测工具,单纯使用cv库来做图像处理也好,还是神经网络的图像识别也好,都会使用到OpenCV的API.可以说它是现在目标检测的一个基础.</p>\n<h3 id=\"前提注意\"><a href=\"#前提注意\" class=\"headerlink\" title=\"前提注意\"></a>前提注意</h3><p>通常OpenCV对于图像的三通道是遵循BGR的规律,也就是一幅彩色图像,它的第一层(下标为0)是Blue,后面2层依次为Green,Red.   在Python中可以直接对图像进行索引img[0],在C++中,需要对图像的容器进行索引才能有和Python一样的效果,(容器可以用Python中的张量来解释)也就是img.at<Vec3b>(img.rows,imgcols)[0]. 同时在C++中使用OpenCV的颜色也需要调用函数cv::Scalar,Python直接括号就行.</p>\n<h3 id=\"使用\"><a href=\"#使用\" class=\"headerlink\" title=\"使用\"></a>使用</h3><p>OpenCV的常用功能有,将图像二值化,图像通道分离,进行颜色通道过滤,检测物体边缘,在图像上绘制图形,分割图像,当然也能拼贴新图像,过滤噪点,滤波通道筛选.总之就是对图像的像素层级进行一系列处理.</p>\n<p>这些是它的基底功能,后面的那些提取roi,车辆检测,赛道检测,车牌分割检测,都是靠人的创造力产生的.(赞美!)</p>\n<p>使用上.<em>[新手上路,就记函数,想学东西,还得回看]</em>.总之一开始就直接总体认知.</p>\n<p>首先是获取图像:    如果是图片那么就cv.imread(“你图片的绝对路径”),它就近进来了(.如果是C++那么就是需要先定义一个矩阵给图像cv::Mat value ,然后传入给变量value,value &#x3D; cv::imread(“你图片的绝对路径”)——-(C++和Python在OpenCV上没过多需要注意的差异,小地方差异我难得写,直接来问,我这里主要用Python演示)</p>\n<p>如果需要读进来的是视频呢?视频不就是一张张图片拼凑起来麻,opencv读取视频的方法是</p>\n<p>cv.VideoCapture(“视频的绝对路径”)如果想读如设备,比如摄像头的画面,那么就是cv.VideoCapture(0  一般是在使用设备上自带的摄像头,比如笔记本,1是外接设备,比如外接一个的USB摄像头.     除此之外,想要选定设备,Windows下找寻端口,一般USB摄像头连接后的COM号. Linux系统下则是设备路径,如&#x2F;dev&#x2F;video(这里的数字对应摄像头设备)),     用变量value来接收,此时是得到视频流的一系列数据,然后进一步操作得到视频frame,对应的函数是read(),两个返回值: _,frame &#x3D; value.read().好,此时我们得到了视频图像frame,但是它是不会变动的,因为没有时间戳,我们设定一个while循环,同时加上让frame播放的帧率,如:</p>\n<p>while True:</p>\n<p>   cv.waitKey(多久显示视频的下一张图片)    #这里使用从cv.waitKey()函数来规定帧率</p>\n<p>   _,frame &#x3D; value.read()              #对的,需要把读取视频函数read放到while中才有连续的视频画面</p>\n<p>   cv.imshow(‘window’,frame)        #通过函数cv.imshow()来显示画面,内置两个参数,一个是窗口名字,一个是图片信息,由于我们是while循环中,每一次while很快,实际上是按我们的帧率显示的单张图片,连起来就是视频了.</p>\n<p>图像获取了,好我们来处理图像.</p>\n<p>cv.cvtColor()函数是改变图像通道的,一般彩色(三色)转灰度(单色)就是cv.cvtColor(你要转的图像,cv.COLOR_BGR2GRAY),然后转二值化图像(黑白图),需要用灰度图像作为输入,不能用彩色(三通道了)</p>\n<p>转二值化的函数为cv.threshold(需要转换图像的灰度图,xx,XX(阈值,大于最大XX,变黑,小于最小xx,为白) ,二值化方法))</p>\n<p>好了,现在得到黑白图了,然后常见的下一步就是找轮廓</p>\n<p>函数   cv.findContours(输入图像,X,X),返回两个值</p>\n<p>      然后根据你找到的轮廓进行轮廓绘制</p>\n<p>      cv.drawContours(绘制在那个图上,轮廓,-1为全部轮廓,其他数字为轮廓下标,颜色, 绘制线条大小,-1为向内填充)</p>\n<p>然后就是颜色过滤(这里是对于HSV色域下来处理),对应函数是cv.inRange(需要过滤的图像,颜色最低阈值,最高阈值),返回的是一个矩阵信息,在python中可以理解为mask,就是一块区域,然后将原图中这块mask区域单独拿出来就能做到颜色过滤的效果了,提取roi区域也是类似的方法,所谓roi就是感兴趣区域,对什么感兴趣呢?这就要根据情况去判断并做处理去找到对应mask了.</p>\n<p>形态学处理:形态学处理是对特征识别一个适应性的调整,它的作用就是对你的图像(一般是二值化)样子进行调整.比如erode(腐蚀)运算和dilate(膨胀)运算,它们是对图像的像素级进行新的变换得到新的图像,在这个基础上的开,闭运算(morphology)起到的效果是一样的.</p>\n<p>形态学处理还可以算上各类滤波,它们的功能大体上是针对图像信息进行一定信息的过滤.总之理解上和信号处理上的滤波所起到的效果是一样的.</p>\n<p>到此基本的东西有了就能做很多了</p>\n<h2 id=\"例子\"><a href=\"#例子\" class=\"headerlink\" title=\"例子\"></a>例子</h2><p>车牌检测:</p>\n<p>![[Pasted image 20230903133514.png]]</p>\n<table>\n<thead>\n<tr>\n<th></th>\n</tr>\n</thead>\n<tbody><tr>\n<td></td>\n</tr>\n<tr>\n<td></td>\n</tr>\n</tbody></table>\n<p>如果要单独获取图上的车牌信息,可以这样来想</p>\n<p>首先它是一张图片,那应该要先导入缓冲区中</p>\n<p>frame &#x3D; cv.imread(“路径”)</p>\n<p>我们想得到的是图中车牌部分的内容,那应该提取车牌所涵盖的roi区域,提取方法取决于你的想象力.</p>\n<p>这里我拿到原图不知道怎么处理,好,先把原图转化为黑白图</p>\n<p>gray &#x3D; cv.cvtColor(frame, cv.COLOR_BGR2GRAY)</p>\n<p>_,threshold &#x3D; cv.threshold(gray, 45,255, cv.THRESH_TRIANGLE)</p>\n<p>然后就得到了黑白图像threshold:</p>\n<p><img src=\"file:///C:/Users/fsosa/AppData/Local/Temp/msohtmlclip1/01/clip_image004.gif\"><br>好的,然后思考,我们想要得到中间的车牌信息,是直接在这张图上进行获取?em…除了车牌包含的信息,我们是最好把其他信息给过滤掉.那些白线阿,点阿.这时就从OpenCV库里去找合适的方法来达成目的就好.比如我想到的是找每个连接体的轮廓,然后按面积来进行过滤.实现如下:</p>\n<p>c,_ &#x3D;  cv.findContours(threshold, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)</p>\n<p>这时我们得到了全图的所有能被找到的轮廓信息c,把他显示出来就像</p>\n<p><img src=\"file:///C:/Users/fsosa/AppData/Local/Temp/msohtmlclip1/01/clip_image006.gif\"><br>em…毕竟是全部,那我们来想一下怎么剔除不要的,算面积?</p>\n<p>通过cv.ContoursArea()倒是可以算拉,然后通过if判断大于一定程度面积的就保留下来,然后就能得到中间的数字轮廓,进而得到数字和地区了是把?对,这是一种方法,但是传统视觉最重要的点是在于根据情况进行调整!!!,这道题上,你如果用面积,那上面那条线其实不是很友好,那么还能加一些前置判断(好,这就是传统视觉麻烦的地方了,为达到目的,需要根据情况调节各类前置参数使得最终有一个良好的检测图像)比如这里我可以加,我这个边缘轮廓的长宽之比,在一定范围上,欸,我就可以过滤掉长线条和圆点.</p>\n<p>当然你也可以先把车牌的roi区域按照一定方法找到提取出来在对roi区域做,会少很多干扰</p>\n<p>![[Pasted image 20230903133503.png]]</p>\n<table>\n<thead>\n<tr>\n<th></th>\n</tr>\n</thead>\n<tbody><tr>\n<td></td>\n</tr>\n<tr>\n<td></td>\n</tr>\n</tbody></table>\n<p>然后按照一定判断条件得到车牌信息(绿色部分),然后单独把每一个信息截取下来,就是根据你找到的边框(绿色)然后对原始图像截取这部分就行,形如:</p>\n<p>for i in c:</p>\n<p>x,y,w,h &#x3D; cv.boundingRect(i)    #获取边框的角点坐标</p>\n<p>然后根据你的条件过滤,得到绿色的边框信息,再创建一个数组,把车牌信息存进去</p>\n<p>picture &#x3D; list()</p>\n<p>picture.append(frame[y:y+h,x:x+w])</p>\n<p>![[Pasted image 20230903133439.png]]</p>\n<table>\n<thead>\n<tr>\n<th></th>\n</tr>\n</thead>\n<tbody><tr>\n<td></td>\n</tr>\n<tr>\n<td></td>\n</tr>\n</tbody></table>\n<p>OK,后续如果要获得这个信息具体是什么,应为车牌的样式比较统一,网上把这些数字和地区缩写弄下来,和你picture里面的进行像素匹配,给一个阈值就知道车牌上信息是多少了.</p>\n<p>如果得到黑白图后想到过滤信息没想到滤波和形态学处理的,em…</p>\n<p>那这道题能不能用颜色通道来做???  em…,车牌是蓝色的,字是白色的,而且这图的车身颜色</p>\n<p><img src=\"file:///C:/Users/fsosa/AppData/Local/Temp/msohtmlclip1/01/clip_image012.gif\"><br>总之我很难把它的数字单独调出来,那么这一步不能这样考虑,它是不合理的一步(这就是传统视觉的根据场景,因材施教)</p>\n<p>差不多了,其他的赛道检测,rm上的灯条识别如果是传统视觉也都是差不多的切入点,但解题思路肯定是根据情况来做的,好比让你现场做菜,食材和工具是现实情况,你会的烹饪方法和菜谱相当于OpenCV它这个库给你的函数.</p>\n<h2 id=\"HOG特征提取-SVM分类\"><a href=\"#HOG特征提取-SVM分类\" class=\"headerlink\" title=\"HOG特征提取+SVM分类\"></a>HOG特征提取+SVM分类</h2><p>传统视觉也能做训练,也能做推理,一般靠HOG+SVM做目标检测,可以理解是一个低端的神经网络目标检测.HOG特征提取,是.具体是通过从图像像素单位做提取,记录某一像素向某个方向的灰度变化(突变),按照这类变化规律记录想要检测的物体.(把图片当作矩阵,每个像素代表0-255的数字,按一定规律去找一部分像素周边像素数字的变化幅度,方向[梯度],然后记录这个规律,再给一张新图,新图中相同元素的像素变化和之前我们找到的规律一样或者相似那算检测到了这个物体的位置)但是如果按每一个像素去找似乎太慢,同时像素规模大了,对这个规律的找寻会更混乱.于是要自行划定判断像素块大小(cell)以及找寻整张图规律时是按照多少个像素块一起进行这个规律的判断(block).HOG特征提取也是需要样本集的,</p>\n<p>一般只用正负样本就够了.</p>\n<p>总之它是根据图像像素进行的特征提取,这就注定了它无法直接用于复杂图像的特征提取,至于SVM,就是支持向量机麻,做最大分类,在这里,它的作用就是把训练的模型做分类,如果只是检测出目标倒是不用太在意,如果需要具体知道检测到的是什么则需要SVM把模型分类.</p>\n<p>我们那这个玉米为例:</p>\n<table>\n<thead>\n<tr>\n<th></th>\n</tr>\n</thead>\n<tbody><tr>\n<td></td>\n</tr>\n<tr>\n<td></td>\n</tr>\n</tbody></table>\n<p>怎么说,如果要通过这幅图把玉米的特征提取出来,em…可以做,但是这个背景其实不好看,很容易提取错误的特征</p>\n<p>$$<br>![[+]]</p>\n<h2 id=\"模型（model）\"><a href=\"#模型（model）\" class=\"headerlink\" title=\"模型（model）\"></a>模型（model）</h2><p>所谓模型，就是一整个计算流程，上面我们说到根据计算图得到输出，其实模型就是计算图的抽象化，它可以分为多个层级，卷积、池化、全连接，最后到输出。深度学习的这个学习过程，最后得到的是整个模型，包括中间的各类参数和优化器这些参与计算的元素。可以通过netron这类模型可视化工具来帮助理解模型是什么。</p>\n<h4 id=\"模型容器\"><a href=\"#模型容器\" class=\"headerlink\" title=\"模型容器\"></a>模型容器</h4><p>容器起到类似于封装的功能，把多个模型可实现功能结合在一个包中，在使用时会更简洁。tensor常见的容器有<strong>nn.Sequetial</strong>， <strong>nn.ModuleList</strong>之类的。</p>\n<h2 id=\"网络层\"><a href=\"#网络层\" class=\"headerlink\" title=\"网络层\"></a>网络层</h2><h3 id=\"卷积（Conv）\"><a href=\"#卷积（Conv）\" class=\"headerlink\" title=\"卷积（Conv）\"></a>卷积（Conv）</h3><p>卷积核就是一个单独的计算块，卷积的过程就是计算块在原有数据矩阵中滑行的过程，根据滑行的维度来分几维卷积。它类似于将原有的多个数据通过计算块的计算(卷积)得到一个新的数，这个数会包含被卷积部分的[特征]，最后卷积完的效果就是，原有数据会变小，但是会保留其特征。<br><strong>空洞卷积</strong>：卷积核中有以0填充的部分，主要是以0元素填充来扩大卷积核大小。也有利于扩大感受野。<br>卷积后尺寸的计算：<br>若输入图像大小为I x I，卷积核大小为k x k，卷积核填充(padding)为p，空洞卷积大小(dilation)为d，卷积核步长(stride)为s。通过卷积后的尺寸O为：<br>$$\\begin{aligned}<br>O&#x3D;\\frac{I-d*(k-1)+2*p-1}{s}+1<br>\\end{aligned}$$</p>\n<p>标准卷积核（空洞卷积大小为1，填充宽度为0，步长为1）</p>\n<h3 id=\"转置卷积（ConvTranspose）\"><a href=\"#转置卷积（ConvTranspose）\" class=\"headerlink\" title=\"转置卷积（ConvTranspose）\"></a>转置卷积（ConvTranspose）</h3><p>转置卷积也叫反卷积（Deconvolution），卷积是对图像进行下采样，那么反卷积就是进行上采样，将图像扩大，对应反卷积后的尺寸O，（参数同上）：<br>$$O&#x3D;(I-1)<em>s-2</em>p+d*(k-1)+outpadding+1$$<br>out_padding这个参数为了确保在反卷积过程中，输出的尺寸的唯一性，也就是确定输出尺寸的大小<br>转置卷积后的图像一般都有棋盘格效应，就是画面最上层会有一层棋盘格的效果。</p>\n<h3 id=\"池化（Pool）\"><a href=\"#池化（Pool）\" class=\"headerlink\" title=\"池化（Pool）\"></a>池化（Pool）</h3><p>降采样，保留<strong>特征</strong>降低维度，扩大感受野。与卷积把每个块都进行运算不同，池化是从块中选取特定元素(常见的是提取块中最大值)，来达到保留特征，较低维度功能。反池化（Unpool）则是根据给定的元素进行一定大小的还原(扩充)，一般周围元素都用0来填充。上采样和反池化有点相似，也是将给定元素进行一定区域的扩大，不过上采样扩大后周边填充元素与扩大的元素相同。![[Pasted image 20230630102348.png]]</p>\n<h3 id=\"全连接\"><a href=\"#全连接\" class=\"headerlink\" title=\"全连接\"></a>全连接</h3><p>全连接层，或者叫<strong>线性层</strong>，一般在最后输出的前一步，全连接层上每个<strong>神经元</strong>与上一层的所有神经元相连接。进行最终的计算求得输出。</p>\n<h3 id=\"激活函数层\"><a href=\"#激活函数层\" class=\"headerlink\" title=\"激活函数层\"></a>激活函数层</h3><p>神经网络是层状结构，运行计算的层一般不显示出来，称为<strong>隐藏层</strong>：<br>$$\\begin{aligned}<br>&amp;第一个隐藏层H_1&#x3D;X<em>W_1\\<br>&amp;第二个隐藏层H_2&#x3D;H_1</em>W_2\\<br>&amp;…\\<br>&amp;最后输出层H_n&#x3D;H_{n-1}*W_n<br>\\end{aligned}$$<br>可以看见，在不引入其它函数时，如果整个变换过程为线性变换，那么它不会有[非线性]变换或者其他更复杂变换的变化。激活函数层则是用来引发这种变换的。比如上面我们提到的逻辑回归中sigmod函数，它就是个非线性的函数，在激活层引入它，就会让后续计算的变得非线性。常见的还有tanh函数，和ReLU函数。不同非线性函数的选择会对梯度下降的下降过程有影响，比如梯度消失和梯度爆炸，可以通过函数的表现形式看出（因为梯度下降过程还是一个求导的过程，导数在二维上可以看作斜率嘛）。</p>\n<h3 id=\"初始化\"><a href=\"#初始化\" class=\"headerlink\" title=\"初始化\"></a>初始化</h3><p>之前说了，在网络层计算过程中的参数是随机取的，这就会影响每一层之间数据的[跨度]过大或者过小，而每经过一个有n个神经元的网络层，方差会被扩大n倍。为了防止网络层计算时产生的梯度消失（0）或梯度爆炸（无穷大），初始化保证了每一层输出的方差（随机变量平方的期望减去期望的平方$D(X)&#x3D;E(X^2)-(E(X))^2$代表了<strong>数据的波动情况</strong>）在一个可接受范围。</p>\n<h2 id=\"模型保存\"><a href=\"#模型保存\" class=\"headerlink\" title=\"模型保存\"></a>模型保存</h2><p>pytorch中保存模型是通过torch.save。不同框架保存模型的方式不同，导出的模型样式也不同，不过内部的基本东西还是参数和权重。不过不同类型模型之间也有方法可以转换（export）就是了。不同架构上支持的模型也不同，比如edgeboard上主要支持自家的paddle。一般模型保存需要注意几个点，也是目前主流的框架中都有的，epoch（迭代多少轮），iteration（使用batch对模型参数进行一次更新），batch（每一次更新处理多少数据）；训练多少epoch可以选定保存一份模型，并在中断或者训练完后找出最优的模型（损失函数最小）。这种不够直观，所以可以采用Tensorboard，它能对你训练的模型进行可视化，包括训练过程中损失函数的走向，各类参数的变化情况。<br>模型训练的话，一般来讲是把原生样本（可以是声音，图片…不过不同类型的样本对应提取成分不同，比如语言训练不只是输入声音，还要对其进行分帧，加窗，后面的梅尔频谱处理之类的）分为：训练集（作为输入X），测试集（作为真实输出Y，用来做损失函数的），验证集（这个很少有用到，就是拿你训练的模型再用样本做检测）。</p>\n","text":"传统视觉OpenCV作为最基本的目标检测工具,单纯使用cv库来做图像处理也好,还是神经网络的图像识别也好,都会使用到OpenCV的API.可以说它是现在目标检测...","link":"","photos":[],"count_time":{"symbolsCount":"6.5k","symbolsTime":"6 mins."},"categories":[{"name":"传统视觉","slug":"传统视觉","count":1,"path":"api/categories/传统视觉.json"}],"tags":[{"name":"opencv函数","slug":"opencv函数","count":1,"path":"api/tags/opencv函数.json"},{"name":"hog+svm检测","slug":"hog-svm检测","count":1,"path":"api/tags/hog-svm检测.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E4%BC%A0%E7%BB%9F%E8%A7%86%E8%A7%89\"><span class=\"toc-text\">传统视觉</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#OpenCV\"><span class=\"toc-text\">OpenCV</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%89%8D%E6%8F%90%E6%B3%A8%E6%84%8F\"><span class=\"toc-text\">前提注意</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E4%BD%BF%E7%94%A8\"><span class=\"toc-text\">使用</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E4%BE%8B%E5%AD%90\"><span class=\"toc-text\">例子</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#HOG%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96-SVM%E5%88%86%E7%B1%BB\"><span class=\"toc-text\">HOG特征提取+SVM分类</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%A8%A1%E5%9E%8B%EF%BC%88model%EF%BC%89\"><span class=\"toc-text\">模型（model）</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E6%A8%A1%E5%9E%8B%E5%AE%B9%E5%99%A8\"><span class=\"toc-text\">模型容器</span></a></li></ol></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E7%BD%91%E7%BB%9C%E5%B1%82\"><span class=\"toc-text\">网络层</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%8D%B7%E7%A7%AF%EF%BC%88Conv%EF%BC%89\"><span class=\"toc-text\">卷积（Conv）</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E8%BD%AC%E7%BD%AE%E5%8D%B7%E7%A7%AF%EF%BC%88ConvTranspose%EF%BC%89\"><span class=\"toc-text\">转置卷积（ConvTranspose）</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E6%B1%A0%E5%8C%96%EF%BC%88Pool%EF%BC%89\"><span class=\"toc-text\">池化（Pool）</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%85%A8%E8%BF%9E%E6%8E%A5\"><span class=\"toc-text\">全连接</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E5%B1%82\"><span class=\"toc-text\">激活函数层</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%88%9D%E5%A7%8B%E5%8C%96\"><span class=\"toc-text\">初始化</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%A8%A1%E5%9E%8B%E4%BF%9D%E5%AD%98\"><span class=\"toc-text\">模型保存</span></a></li></ol></li></ol>","author":{"name":"shol","slug":"blog-author","avatar":"http://localhost:4000/static/img/d4.jpg","link":"/","description":"","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"hidden":false,"prev_post":{},"next_post":{"title":"ROS","uid":"d1785060d540402d26f62361462e606a","slug":"ROS","date":"2023-09-06T14:25:57.000Z","updated":"2023-09-22T08:35:50.813Z","comments":true,"path":"api/articles/ROS.json","keywords":null,"cover":[],"text":" 用途ROS类似一个数据传输的管道,也提供接口,好比cpu和其他设备间信息交互的总线.一开始是为解决机器人上信息传输问题,因而目前ROS开发社区中对这一块的库可...","link":"","photos":[],"count_time":{"symbolsCount":"1.7k","symbolsTime":"2 mins."},"categories":[],"tags":[],"author":{"name":"shol","slug":"blog-author","avatar":"http://localhost:4000/static/img/d4.jpg","link":"/","description":"","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}}}
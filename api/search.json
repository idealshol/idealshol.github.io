[{"id":"cdd0edf7fdd8b10c4ae1947cffd17b2c","title":"OpenCV","content":"传统视觉OpenCV作为最基本的目标检测工具,单纯使用cv库来做图像处理也好,还是神经网络的图像识别也好,都会使用到OpenCV的API.可以说它是现在目标检测的一个基础.\n前提注意通常OpenCV对于图像的三通道是遵循BGR的规律,也就是一幅彩色图像,它的第一层(下标为0)是Blue,后面2层依次为Green,Red.   在Python中可以直接对图像进行索引img[0],在C++中,需要对图像的容器进行索引才能有和Python一样的效果,(容器可以用Python中的张量来解释)也就是img.at(img.rows,imgcols)[0]. 同时在C++中使用OpenCV的颜色也需要调用函数cv::Scalar,Python直接括号就行.\n使用OpenCV的常用功能有,将图像二值化,图像通道分离,进行颜色通道过滤,检测物体边缘,在图像上绘制图形,分割图像,当然也能拼贴新图像,过滤噪点,滤波通道筛选.总之就是对图像的像素层级进行一系列处理.\n这些是它的基底功能,后面的那些提取roi,车辆检测,赛道检测,车牌分割检测,都是靠人的创造力产生的.(赞美!)\n使用上.[新手上路,就记函数,想学东西,还得回看].总之一开始就直接总体认知.\n首先是获取图像:    如果是图片那么就cv.imread(“你图片的绝对路径”),它就近进来了(.如果是C++那么就是需要先定义一个矩阵给图像cv::Mat value ,然后传入给变量value,value &#x3D; cv::imread(“你图片的绝对路径”)——-(C++和Python在OpenCV上没过多需要注意的差异,小地方差异我难得写,直接来问,我这里主要用Python演示)\n如果需要读进来的是视频呢?视频不就是一张张图片拼凑起来麻,opencv读取视频的方法是\ncv.VideoCapture(“视频的绝对路径”)如果想读如设备,比如摄像头的画面,那么就是cv.VideoCapture(0  一般是在使用设备上自带的摄像头,比如笔记本,1是外接设备,比如外接一个的USB摄像头.     除此之外,想要选定设备,Windows下找寻端口,一般USB摄像头连接后的COM号. Linux系统下则是设备路径,如&#x2F;dev&#x2F;video(这里的数字对应摄像头设备)),     用变量value来接收,此时是得到视频流的一系列数据,然后进一步操作得到视频frame,对应的函数是read(),两个返回值: _,frame &#x3D; value.read().好,此时我们得到了视频图像frame,但是它是不会变动的,因为没有时间戳,我们设定一个while循环,同时加上让frame播放的帧率,如:\nwhile True:\n   cv.waitKey(多久显示视频的下一张图片)    #这里使用从cv.waitKey()函数来规定帧率\n   _,frame &#x3D; value.read()              #对的,需要把读取视频函数read放到while中才有连续的视频画面\n   cv.imshow(‘window’,frame)        #通过函数cv.imshow()来显示画面,内置两个参数,一个是窗口名字,一个是图片信息,由于我们是while循环中,每一次while很快,实际上是按我们的帧率显示的单张图片,连起来就是视频了.\n图像获取了,好我们来处理图像.\ncv.cvtColor()函数是改变图像通道的,一般彩色(三色)转灰度(单色)就是cv.cvtColor(你要转的图像,cv.COLOR_BGR2GRAY),然后转二值化图像(黑白图),需要用灰度图像作为输入,不能用彩色(三通道了)\n转二值化的函数为cv.threshold(需要转换图像的灰度图,xx,XX(阈值,大于最大XX,变黑,小于最小xx,为白) ,二值化方法))\n好了,现在得到黑白图了,然后常见的下一步就是找轮廓\n函数   cv.findContours(输入图像,X,X),返回两个值\n      然后根据你找到的轮廓进行轮廓绘制\n      cv.drawContours(绘制在那个图上,轮廓,-1为全部轮廓,其他数字为轮廓下标,颜色, 绘制线条大小,-1为向内填充)\n然后就是颜色过滤(这里是对于HSV色域下来处理),对应函数是cv.inRange(需要过滤的图像,颜色最低阈值,最高阈值),返回的是一个矩阵信息,在python中可以理解为mask,就是一块区域,然后将原图中这块mask区域单独拿出来就能做到颜色过滤的效果了,提取roi区域也是类似的方法,所谓roi就是感兴趣区域,对什么感兴趣呢?这就要根据情况去判断并做处理去找到对应mask了.\n形态学处理:形态学处理是对特征识别一个适应性的调整,它的作用就是对你的图像(一般是二值化)样子进行调整.比如erode(腐蚀)运算和dilate(膨胀)运算,它们是对图像的像素级进行新的变换得到新的图像,在这个基础上的开,闭运算(morphology)起到的效果是一样的.\n形态学处理还可以算上各类滤波,它们的功能大体上是针对图像信息进行一定信息的过滤.总之理解上和信号处理上的滤波所起到的效果是一样的.\n到此基本的东西有了就能做很多了\n例子车牌检测:\n![[Pasted image 20230903133514.png]]\n\n\n\n\n\n\n\n\n\n\n\n\n\n如果要单独获取图上的车牌信息,可以这样来想\n首先它是一张图片,那应该要先导入缓冲区中\nframe &#x3D; cv.imread(“路径”)\n我们想得到的是图中车牌部分的内容,那应该提取车牌所涵盖的roi区域,提取方法取决于你的想象力.\n这里我拿到原图不知道怎么处理,好,先把原图转化为黑白图\ngray &#x3D; cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n_,threshold &#x3D; cv.threshold(gray, 45,255, cv.THRESH_TRIANGLE)\n然后就得到了黑白图像threshold:\n好的,然后思考,我们想要得到中间的车牌信息,是直接在这张图上进行获取?em…除了车牌包含的信息,我们是最好把其他信息给过滤掉.那些白线阿,点阿.这时就从OpenCV库里去找合适的方法来达成目的就好.比如我想到的是找每个连接体的轮廓,然后按面积来进行过滤.实现如下:\nc,_ &#x3D;  cv.findContours(threshold, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n这时我们得到了全图的所有能被找到的轮廓信息c,把他显示出来就像\nem…毕竟是全部,那我们来想一下怎么剔除不要的,算面积?\n通过cv.ContoursArea()倒是可以算拉,然后通过if判断大于一定程度面积的就保留下来,然后就能得到中间的数字轮廓,进而得到数字和地区了是把?对,这是一种方法,但是传统视觉最重要的点是在于根据情况进行调整!!!,这道题上,你如果用面积,那上面那条线其实不是很友好,那么还能加一些前置判断(好,这就是传统视觉麻烦的地方了,为达到目的,需要根据情况调节各类前置参数使得最终有一个良好的检测图像)比如这里我可以加,我这个边缘轮廓的长宽之比,在一定范围上,欸,我就可以过滤掉长线条和圆点.\n当然你也可以先把车牌的roi区域按照一定方法找到提取出来在对roi区域做,会少很多干扰\n![[Pasted image 20230903133503.png]]\n\n\n\n\n\n\n\n\n\n\n\n\n\n然后按照一定判断条件得到车牌信息(绿色部分),然后单独把每一个信息截取下来,就是根据你找到的边框(绿色)然后对原始图像截取这部分就行,形如:\nfor i in c:\nx,y,w,h &#x3D; cv.boundingRect(i)    #获取边框的角点坐标\n然后根据你的条件过滤,得到绿色的边框信息,再创建一个数组,把车牌信息存进去\npicture &#x3D; list()\npicture.append(frame[y:y+h,x:x+w])\n![[Pasted image 20230903133439.png]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nOK,后续如果要获得这个信息具体是什么,应为车牌的样式比较统一,网上把这些数字和地区缩写弄下来,和你picture里面的进行像素匹配,给一个阈值就知道车牌上信息是多少了.\n如果得到黑白图后想到过滤信息没想到滤波和形态学处理的,em…\n那这道题能不能用颜色通道来做???  em…,车牌是蓝色的,字是白色的,而且这图的车身颜色\n总之我很难把它的数字单独调出来,那么这一步不能这样考虑,它是不合理的一步(这就是传统视觉的根据场景,因材施教)\n差不多了,其他的赛道检测,rm上的灯条识别如果是传统视觉也都是差不多的切入点,但解题思路肯定是根据情况来做的,好比让你现场做菜,食材和工具是现实情况,你会的烹饪方法和菜谱相当于OpenCV它这个库给你的函数.\nHOG特征提取+SVM分类传统视觉也能做训练,也能做推理,一般靠HOG+SVM做目标检测,可以理解是一个低端的神经网络目标检测.HOG特征提取,是.具体是通过从图像像素单位做提取,记录某一像素向某个方向的灰度变化(突变),按照这类变化规律记录想要检测的物体.(把图片当作矩阵,每个像素代表0-255的数字,按一定规律去找一部分像素周边像素数字的变化幅度,方向[梯度],然后记录这个规律,再给一张新图,新图中相同元素的像素变化和之前我们找到的规律一样或者相似那算检测到了这个物体的位置)但是如果按每一个像素去找似乎太慢,同时像素规模大了,对这个规律的找寻会更混乱.于是要自行划定判断像素块大小(cell)以及找寻整张图规律时是按照多少个像素块一起进行这个规律的判断(block).HOG特征提取也是需要样本集的,\n一般只用正负样本就够了.\n总之它是根据图像像素进行的特征提取,这就注定了它无法直接用于复杂图像的特征提取,至于SVM,就是支持向量机麻,做最大分类,在这里,它的作用就是把训练的模型做分类,如果只是检测出目标倒是不用太在意,如果需要具体知道检测到的是什么则需要SVM把模型分类.\n我们那这个玉米为例:\n\n\n\n\n\n\n\n\n\n\n\n\n\n怎么说,如果要通过这幅图把玉米的特征提取出来,em…可以做,但是这个背景其实不好看,很容易提取错误的特征\n$$![[+]]\n模型（model）所谓模型，就是一整个计算流程，上面我们说到根据计算图得到输出，其实模型就是计算图的抽象化，它可以分为多个层级，卷积、池化、全连接，最后到输出。深度学习的这个学习过程，最后得到的是整个模型，包括中间的各类参数和优化器这些参与计算的元素。可以通过netron这类模型可视化工具来帮助理解模型是什么。\n模型容器容器起到类似于封装的功能，把多个模型可实现功能结合在一个包中，在使用时会更简洁。tensor常见的容器有nn.Sequetial， nn.ModuleList之类的。\n网络层卷积（Conv）卷积核就是一个单独的计算块，卷积的过程就是计算块在原有数据矩阵中滑行的过程，根据滑行的维度来分几维卷积。它类似于将原有的多个数据通过计算块的计算(卷积)得到一个新的数，这个数会包含被卷积部分的[特征]，最后卷积完的效果就是，原有数据会变小，但是会保留其特征。空洞卷积：卷积核中有以0填充的部分，主要是以0元素填充来扩大卷积核大小。也有利于扩大感受野。卷积后尺寸的计算：若输入图像大小为I x I，卷积核大小为k x k，卷积核填充(padding)为p，空洞卷积大小(dilation)为d，卷积核步长(stride)为s。通过卷积后的尺寸O为：$$\\begin{aligned}O&#x3D;\\frac{I-d*(k-1)+2*p-1}{s}+1\\end{aligned}$$\n标准卷积核（空洞卷积大小为1，填充宽度为0，步长为1）\n转置卷积（ConvTranspose）转置卷积也叫反卷积（Deconvolution），卷积是对图像进行下采样，那么反卷积就是进行上采样，将图像扩大，对应反卷积后的尺寸O，（参数同上）：$$O&#x3D;(I-1)s-2p+d*(k-1)+outpadding+1$$out_padding这个参数为了确保在反卷积过程中，输出的尺寸的唯一性，也就是确定输出尺寸的大小转置卷积后的图像一般都有棋盘格效应，就是画面最上层会有一层棋盘格的效果。\n池化（Pool）降采样，保留特征降低维度，扩大感受野。与卷积把每个块都进行运算不同，池化是从块中选取特定元素(常见的是提取块中最大值)，来达到保留特征，较低维度功能。反池化（Unpool）则是根据给定的元素进行一定大小的还原(扩充)，一般周围元素都用0来填充。上采样和反池化有点相似，也是将给定元素进行一定区域的扩大，不过上采样扩大后周边填充元素与扩大的元素相同。![[Pasted image 20230630102348.png]]\n全连接全连接层，或者叫线性层，一般在最后输出的前一步，全连接层上每个神经元与上一层的所有神经元相连接。进行最终的计算求得输出。\n激活函数层神经网络是层状结构，运行计算的层一般不显示出来，称为隐藏层：$$\\begin{aligned}&amp;第一个隐藏层H_1&#x3D;XW_1\\&amp;第二个隐藏层H_2&#x3D;H_1W_2\\&amp;…\\&amp;最后输出层H_n&#x3D;H_{n-1}*W_n\\end{aligned}$$可以看见，在不引入其它函数时，如果整个变换过程为线性变换，那么它不会有[非线性]变换或者其他更复杂变换的变化。激活函数层则是用来引发这种变换的。比如上面我们提到的逻辑回归中sigmod函数，它就是个非线性的函数，在激活层引入它，就会让后续计算的变得非线性。常见的还有tanh函数，和ReLU函数。不同非线性函数的选择会对梯度下降的下降过程有影响，比如梯度消失和梯度爆炸，可以通过函数的表现形式看出（因为梯度下降过程还是一个求导的过程，导数在二维上可以看作斜率嘛）。\n初始化之前说了，在网络层计算过程中的参数是随机取的，这就会影响每一层之间数据的[跨度]过大或者过小，而每经过一个有n个神经元的网络层，方差会被扩大n倍。为了防止网络层计算时产生的梯度消失（0）或梯度爆炸（无穷大），初始化保证了每一层输出的方差（随机变量平方的期望减去期望的平方$D(X)&#x3D;E(X^2)-(E(X))^2$代表了数据的波动情况）在一个可接受范围。\n模型保存pytorch中保存模型是通过torch.save。不同框架保存模型的方式不同，导出的模型样式也不同，不过内部的基本东西还是参数和权重。不过不同类型模型之间也有方法可以转换（export）就是了。不同架构上支持的模型也不同，比如edgeboard上主要支持自家的paddle。一般模型保存需要注意几个点，也是目前主流的框架中都有的，epoch（迭代多少轮），iteration（使用batch对模型参数进行一次更新），batch（每一次更新处理多少数据）；训练多少epoch可以选定保存一份模型，并在中断或者训练完后找出最优的模型（损失函数最小）。这种不够直观，所以可以采用Tensorboard，它能对你训练的模型进行可视化，包括训练过程中损失函数的走向，各类参数的变化情况。模型训练的话，一般来讲是把原生样本（可以是声音，图片…不过不同类型的样本对应提取成分不同，比如语言训练不只是输入声音，还要对其进行分帧，加窗，后面的梅尔频谱处理之类的）分为：训练集（作为输入X），测试集（作为真实输出Y，用来做损失函数的），验证集（这个很少有用到，就是拿你训练的模型再用样本做检测）。\n","slug":"OpenCV","date":"2023-09-06T17:31:40.000Z","categories_index":"传统视觉","tags_index":"opencv函数,hog+svm检测","author_index":"shol"},{"id":"d1785060d540402d26f62361462e606a","title":"ROS","content":"\n用途ROS类似一个数据传输的管道,也提供接口,好比cpu和其他设备间信息交互的总线.一开始是为解决机器人上信息传输问题,因而目前ROS开发社区中对这一块的库可以说很丰富了(包括处理各类传感器信息,控制命令,节点间的通信)比如,在同台电脑同一操作系统上,一边用仿真软件做机械臂仿真(这里就当用模型是URDF或axcro一类)那我可以写一段ROS程序来获取仿真中机械臂的运动,同时写发布函数,再开个matlab,下载相应库,再写段接收函数,就能获取机械臂的运动数据,同时在matlab上进行反运动学处理(IK)获取每个电机需要转动角.\nROS1和ROS2ROS每一段时间(4year?)会更新一次版本,同时官方对每个版本也有一定维护时期,目前(2023.9.22)ROS1算是已经到头了.\n使用(越成熟的,上手越顺滑)\n\nROS1只适配linux系统   || ROS2可以跨平台,支持win,linux,mac\nROS1针对C++和Python的库为roscpp和rospy || ROS2针对C++和Python的库为rclpp和rclpy\nROS1中的节点和消息由一个Master管理,需要在终端中运行 roscore 来启动,后续才可以运行节点和通信 || ROS2采用DDS作为中间层,内部有用c语言实现的rmw库来和DDS直接交互\nROS1中用catkin tool来编译包 || ROS2中用colcon tool来做编译\nROS1中python文件运行相对方便,调试也轻松不用重新编译 || ROS2中python程序运行需要编写setup.py文件来指定入口,且修改程序需要重新编译  (待修正)\nROS1和ROS2可以共存,但是不能同时在环境变量中启用\n\nROS1和ROS2的一些基础信息\nROS作为数据传输工具,具有3种传输方式[topic,service,action],有一个类似的[parameter.service].**Topic:*是一类数据同步*传输方案,节点间通过publisher和subscriber进行数据收发.**Service:*是一类数据异步*传输方案,节点间通过server和client进行数据收发.**Action:*是一类数据指定*传输方案,通过按一定频率发布数据,同时接收返回值(若中间没有其他传输干扰)一直执行到达成目标,节点间通过(Action)server和(Action)client.\n\n[launch]文件类似于bash脚本,可以一件执行多个文件,不过碍于本身是xml类型,能做的功能好像也只限于启动文件.内有一些标签可以添加配置信息,不过也是服务于ROS和连接设备这一方面的了.  运行一个launch文件ROS采用\n\n\n\n\n\n\n\n\n\n  roslaunch package_name launch_name &amp;&amp; ros2 launch package_name launch_name (一般launch也是放在功能包中)\n\n[工作空间]就是你项目的repository,也是你采用编译工具的目录.一般是工作空间中创建一个src文件夹来存放[功能包],每个功能包中又存放你的源文件和环境依赖信息(CMakelist和package),当你在工作空间目录编译(cmake或者colcon)后,当前目录会出现build,install,log目录,用来存放历史log和你的包配置信息.运行一个节点ROS采用 \n\n\n\n\n\n\n\n\n\n  rosrun package_name node_name &amp;&amp; ros2 run package_name node_name (如果是ROS2中的python文件,节点名要去setup.py中写)\n\n[rqt]可以用来查看你运行的节点连接情况\n\n\n\n\n\n\n\n\n\n  rosrun rqt_graph_tree rqt_graph_tree &amp;&amp; ros2 run rqt_graph_tree rqt_graph_tree 可根据当前内存中节点运行情况,生成连接图\n\n\n","slug":"ROS","date":"2023-09-06T14:25:57.000Z","categories_index":"","tags_index":"","author_index":"shol"},{"id":"abeaebbd0b0f1648891139ac7999d458","title":"神经网络","content":"深度学习\n概念pytorch、tensorflow …  这些都是，深度学习的框架，而pytorch为动态，tensorflow为静态(这里就在对计算图进行讨论了)，静态图是把计算图构建好，包括其中的参数，然后输入数据根据参数得到输出；动态图则是先给出前面部分运算参数，根据输入值与前面参数的计算结果决定后面的图应该怎么构建。所谓框架呢，就是深度学习的一整套代码实现的一个流程。比如从输入一个数据到中间的计算，包括引入损失函数、学习率、反向传播、梯度下降、卷积、全链接……一系列流程，最终得到输出，这就是一个深度学习的过程，实现的代码就是框架。pytorch是在tensor(张量)基础上开发的，所谓张量呢如图可直观明白，由于pytorch是在python上进行的，其中会用到torch库，在一些机器学习框架比如yolo中会遇到这些函数就是了（函数能实现的功能蛮多的，包括自动求导获取梯度，张量的创建和变换…）。![[Pasted image 20230629023312.png]]\n一般我们做深度学习都有一个概念，它是一个学习的过程，那肯定是有误差的，关于在真实值和误差之间，一般以线性回归方程来表示这个过程。\n\n\n\n\n\n\n\n\n\n通过分析因变量（y）与自变量（x）的变化关系，形如：$$y&#x3D;wx+b$$,我们需要的就是w和b的数值\n我们所谓的损失函数就是预测值（$\\widehat{y}$）和真实值（y）之间的均方差。形如：$$\\frac{1}{m} \\sum_{i&#x3D;1}^{m}(y_i-\\widehat{y_i})^2$$当采用梯度下降寻找最优时，此时参数会自己[根据当前的情况进行更新]，影响更新幅度的就是学习率，如我们令学习率为（lr）那么要求的参数w，b更新形如：$$w&#x3D;w-lrw.grad （w.grad为函数关于参数w的偏导）$$$$b&#x3D;b-lrb.grad$$梯度下降，结合反向传播，在计算图中的使用情形类似；你扔进去一个X，然后给给Y，中间参数乱写，然后X会根据中间的计算得到输出，再结合对Y的比较进行中间参数的更新。学习率呢，会影响的时梯度下降时你下的幅度，会陷入局部最优和全局最优的情况。\n计算图对这样一个计算图，按照上面的说法，确定一个输入X&#x3D;2与已知结果Y&#x3D;6，其他为中间参数。而$a&#x3D;x+w，b&#x3D;w+1，y&#x3D;a*b$   是计算图的看法。对其求导则涉及到反向传播的内容\n![[Pasted image 20230629030506.png]]\n反向传播（BP）它是干嘛的？我的理解，他就是对前向传播(通过一开的计算图[此时各参数是随机给定]和输入值得到输出值)得到的结果和真实值进行比较，然后做一个逆推，逆推的目的是通过求导然后得到各参数的值，并且进行一定程度上的调整，最终目的就是想让前向传播的输出值与真实值的误差(损失函数)尽可能的小\n通过求导进行反向的传导，其中会涉及到优化器，优化器在反向传播中指引各个参数调整到合适大小。而之前提到的梯度下降法（gradient descent），就是在反向传播中用到的一种优化器。此外还有随机梯度下降（SGD）和批量梯度下降（BGD）之间的差别在于更新参数的方程不同。在上图中，对w的数值进行更新（先算出损失函数对应偏导数，根据链式法则，再带入优化器算法进行参数值更新）：$$ΔE(w_t)&#x3D;\\frac{δy}{δw}&#x3D;\\frac{δy}{δa}\\frac{δa}{δw}+\\frac{δy}{δb}\\frac{δb}{δy}&#x3D;b1+a1…、（E为损失函数）$$学习率：lrGD：$w_{t+1}&#x3D;w_t-lrΔE(w_t)$BGD：$w_{t+1}&#x3D;w_t-lr\\sum_{i&#x3D;1}^{n}ΔE(w_t，x_i，y_i)、（x_i,y_i为当前网络层的输入和输出）$SGD:$w_{t+1}&#x3D;w_t-lr*g_t、（g_t&#x3D;ΔE(w_t，x_t，y_t)，从n个样本中随机选择一个样本）$此外还有其他的一些优化器方法（也是蛮多的）\n逻辑回归（logistic regression）不同于之前的y与x线性回归的关系，逻辑回归一般是用来解决二分类模型的，比较常见的函数有sigmod函数，形如：$$y&#x3D;f(z)&#x3D;\\frac{1}{1+e^{-z}}，z&#x3D;wx+b$$$$result&#x3D;\\begin{cases}0,&amp; \\text{y$\\leq$0.5}\\1,&amp; \\text{y&gt;0.5}\\end{cases}\n","slug":"text1","date":"2023-09-06T14:25:19.000Z","categories_index":"","tags_index":"","author_index":"shol"},{"id":"b9663f58f18133b35bfe243f3e916a80","title":"Hello World","content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.\nQuick StartCreate a new post$ hexo new \"My New Post\"\n\nMore info: Writing\nRun server$ hexo server\n\nMore info: Server\nGenerate static files$ hexo generate\n\nMore info: Generating\nDeploy to remote sites$ hexo deploy\n\nMore info: Deployment\n","slug":"hello-world","date":"2023-09-06T14:22:00.639Z","categories_index":"","tags_index":"","author_index":"shol"}]